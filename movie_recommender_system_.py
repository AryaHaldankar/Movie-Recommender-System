# -*- coding: utf-8 -*-
"""Movie Recommender System .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cyMLhZz1jfo5wpHKd9ST2jLydVgpnpiI
"""

# from google.colab import drive
# drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import scipy.io
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

"""## 2. Recommender Systems

> In this part of the exercise, you will implement the collaborative filtering learning algorithm and apply it to a dataset of movie ratings. This dataset consists of ratings on a scale of $1$ to $5$. The dataset has $n_u = 943$ users, and $n_m = 1682$ movies.

### 2.1 Movie Ratings Dataset

* Matrix $Y$ (num_movies x num_users): ratings $y^{(i,j)}$ (from 1 to 5)
* Matrix $R$: binary where $R(i,j)=1$ if user $j$ gave a rating to movie $i$, and $R(i,j)=0$ otherwise.
* Matrix $X$: each row corresponds to the feature vector $x^{(i)}$ for the i-th movie.
* Matrix $Theta$: each row corresponds to one parameter vector $\theta^{(j)}$ for the j-th user.
"""

mat = scipy.io.loadmat('data/ex8_movies.mat')
Y = mat['Y']
R = mat['R']

mat2 = scipy.io.loadmat('data/ex8_movieParams.mat')
X = mat2['X']
Theta = mat2['Theta']
num_users = mat2['num_users']
num_movies = mat2['num_movies']
num_features = mat2['num_features']

f'Average rating for movie 1 (Toy Story): {np.mean(Y[0, R[0,:]==1])} / 5'

plt.imshow(Y, extent=[0,1000,1600,0], aspect='auto')
plt.title('Ratings Matrix');
plt.xlabel('Users');
plt.ylabel('Movies');

"""### 2.2 Collaborative Filtering Learning Algorithm

> The collaborative filtering algorithm in the setting of movie recommendations considers a set of n-dimensional parameter vectors $x^{(1)} , ..., x^{(n_m)}$ and $\theta^{(1)},...,\theta^{(n_u)}$, where the model predicts the rating for movie $i$ by user $j$ as $y^{(i,j)} = (\theta^{(j)})^T x^{(i)}$. Given a dataset that consists of a set of ratings produced by some users on some movies, you wish to learn the parameter vectors $x^{(1)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)}$ that produce the best fit (minimizes the squared error).

#### 2.2.1 Collaborative filtering cost function (without regularization)

$$ J(x^{(1)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)}) = \frac{1}{2}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^T x^{(i)}-y^{(i,j)})^2$$
"""

def cofi_cost_func(params, Y, R, num_users, num_movies, num_features, lambda_r):
    X = np.reshape(params[:num_movies*num_features], newshape=(num_movies, num_features), order='F')
    Theta = np.reshape(params[num_movies*num_features:], newshape=(num_users, num_features), order='F')

    C = np.subtract(X.dot(Theta.T), Y) ** 2
    J = np.sum(np.sum(R*C)) / 2
    return J

#reduce dataset to test
num_users = 4
num_movies = 5
num_features = 3
X = X[:num_movies, :num_features]
Theta = Theta[:num_users, :num_features]
Y = Y[:num_movies, :num_users]
R = R[:num_movies, :num_users]

J = cofi_cost_func(np.hstack((X.ravel(order='F'), Theta.ravel(order='F'))),
                   Y, R, num_users, num_movies, num_features, 0)
print('Cost at loaded parameters: ', J)
print('\t(this value should be about 22.22)')

"""#### 2.2.2 Collaborative filtering gradient (without regularization)

$$ \frac{\partial J}{\partial x_k^{(i)}} = \sum_{j:r(i,j)=1}((\theta^{(j)})^T x^{(i)}-y^{(i,j)})\theta_k^{(j)} $$

$$ \frac{\partial J}{\partial \theta_k^{(j)}} = \sum_{i:r(i,j)=1}((\theta^{(j)})^T x^{(i)}-y^{(i,j)})x_k^{(i)} $$
"""

def cofi_cost_func(params, Y, R, num_users, num_movies, num_features, lambda_r):
    X = np.reshape(params[:num_movies*num_features], newshape=(num_movies, num_features), order='F')
    Theta = np.reshape(params[num_movies*num_features:], newshape=(num_users, num_features), order='F')

    C = np.subtract(X.dot(Theta.T), Y) ** 2
    J = np.sum(np.sum(R*C)) / 2

    X_grad = np.zeros(X.shape)
    Theta_grad = np.zeros(Theta.shape)

    for i in range(num_movies):
        idx = np.argwhere(R[i,:]==1).T[0]
        X_grad[i,:] = np.subtract(X[i,:].dot(Theta[idx,:].T), Y[i,idx]).dot(Theta[idx,:])

    for j in range(num_users):
        idx = np.argwhere(R[:,j]==1).T[0]
        Theta_grad[j,:] = np.subtract(X[idx,:].dot(Theta[j,:].T), Y[idx,j]).T.dot(X[idx,:])

    grad = np.hstack((X_grad.ravel(order='F'), Theta_grad.ravel(order='F')))

    return J, grad

"""##### Checking Gradients (without regularization)"""

def compute_numerical_gradient(theta, Y, R, num_users, num_movies, num_features, lambda_r):
    e = 0.0001
    num_grad = np.zeros(theta.shape)
    perturb = np.zeros(theta.shape)
    for p in range(len(theta)):
        perturb[p] = e
        loss1,_ = cofi_cost_func(theta-perturb, Y, R, num_users, num_movies, num_features, lambda_r)
        loss2,_ = cofi_cost_func(theta+perturb, Y, R, num_users, num_movies, num_features, lambda_r)
        num_grad[p] = (loss2-loss1)/(2*e)
        perturb[p] = 0
    return num_grad

def check_cost_function(lambda_r=0):
    X_t = np.random.uniform(0,1,(4,3))
    Theta_t = np.random.uniform(0,1,(5,3))

    Y = X_t.dot(Theta_t.T)
    Y[np.random.uniform(0,1,Y.shape)>0.5] = 0
    R = np.zeros(Y.shape)
    R[Y!=0] = 1

    X = np.random.normal(size=X_t.shape)
    Theta = np.random.normal(size=Theta_t.shape)
    num_users = Y.shape[1]
    num_movies = Y.shape[0]
    num_features = Theta_t.shape[1]

    params = np.hstack((X.ravel(order='F'), Theta.ravel(order='F')))

    cost, grad = cofi_cost_func(params, Y, R, num_users, num_movies, num_features, lambda_r)
    num_grad = compute_numerical_gradient(params, Y, R, num_users, num_movies, num_features, lambda_r)

    print('The columns should be very similar...')
    for i, j in zip(num_grad, grad):
        print(i,j)

    diff = np.linalg.norm(num_grad-grad)/np.linalg.norm(num_grad+grad)
    print('''If your cost function implementation is correct, then the relative difference will
             be small (less than 1e-9). Relative Difference:''', diff)

check_cost_function()

"""#### 2.2.3 Regularized cost function

$$ J(x^{(1)},...,x^{(n_m)},\theta^{(1)},...,\theta^{(n_u)}) = \frac{1}{2}\sum_{(i,j):r(i,j)=1}((\theta^{(j)})^T x^{(i)}-y^{(i,j)})^2 +
\Big(\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2 \Big) + \Big(\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2 \Big)$$
"""

def cofi_cost_func(params, Y, R, num_users, num_movies, num_features, lambda_r):
    X = np.reshape(params[:num_movies*num_features], newshape=(num_movies, num_features), order='F')
    Theta = np.reshape(params[num_movies*num_features:], newshape=(num_users, num_features), order='F')

    C = np.subtract(X.dot(Theta.T), Y) ** 2
    J = np.sum(np.sum(R*C)) / 2 + ((lambda_r/2)*np.sum(np.sum(Theta**2))) + ((lambda_r/2)*np.sum(np.sum(X**2)))

    X_grad = np.zeros(X.shape)
    Theta_grad = np.zeros(Theta.shape)

    for i in range(num_movies):
        idx = np.argwhere(R[i,:]==1).T[0]
        X_grad[i,:] = np.subtract(X[i,:].dot(Theta[idx,:].T), Y[i,idx]).dot(Theta[idx,:])

    for j in range(num_users):
        idx = np.argwhere(R[:,j]==1).T[0]
        Theta_grad[j,:] = np.subtract(X[idx,:].dot(Theta[j,:].T), Y[idx,j]).T.dot(X[idx,:])

    grad = np.hstack((X_grad.ravel(order='F'), Theta_grad.ravel(order='F')))

    return J, grad

J, _ = cofi_cost_func(np.hstack((X.ravel(order='F'), Theta.ravel(order='F'))),
                   Y, R, num_users, num_movies, num_features, 1.5)
print('Cost at loaded parameters (lambda = 1.5):', J)
print('\t(this value should be about 31.34)')

"""#### 2.2.4 Regularized gradient

$$ \frac{\partial J}{\partial x_k^{(i)}} = \sum_{j:r(i,j)=1}((\theta^{(j)})^T x^{(i)}-y^{(i,j)})\theta_k^{(j)} + \lambda x_k^{(i)}$$

$$ \frac{\partial J}{\partial \theta_k^{(j)}} = \sum_{i:r(i,j)=1}((\theta^{(j)})^T x^{(i)}-y^{(i,j)})x_k^{(i)} + \lambda \theta_k^{(j)}$$


"""

def cofi_cost_func(params, Y, R, num_users, num_movies, num_features, lambda_r):
    X = np.reshape(params[:num_movies*num_features], newshape=(num_movies, num_features), order='F')
    Theta = np.reshape(params[num_movies*num_features:], newshape=(num_users, num_features), order='F')

    C = np.subtract(X.dot(Theta.T), Y) ** 2
    J = np.sum(np.sum(R*C)) / 2 + ((lambda_r/2)*np.sum(np.sum(Theta**2))) + ((lambda_r/2)*np.sum(np.sum(X**2)))

    X_grad = np.zeros(X.shape)
    Theta_grad = np.zeros(Theta.shape)

    for i in range(num_movies):
        idx = np.argwhere(R[i,:]==1).T[0]
        X_grad[i,:] = np.subtract(X[i,:].dot(Theta[idx,:].T), Y[i,idx]).dot(Theta[idx,:]) + (lambda_r * X[i,:])

    for j in range(num_users):
        idx = np.argwhere(R[:,j]==1).T[0]
        Theta_grad[j,:] = np.subtract(X[idx,:].dot(Theta[j,:].T), Y[idx,j]).T.dot(X[idx,:]) + (lambda_r * Theta[j,:])

    grad = np.hstack((X_grad.ravel(order='F'), Theta_grad.ravel(order='F')))

    return J, grad

check_cost_function(1.5)

"""### 2.3 Learning movie recommendations"""

with open('data/movie_ids.txt', encoding='latin-1') as f:
    content = f.readlines()

movie_list = [' '.join(line.split()[1:]) for line in content]

len(movie_list)

movie_list[:5]

my_ratings = np.zeros((1682, 1))
my_ratings[0] = 4
my_ratings[10] = 4
my_ratings[21] = 5
my_ratings[70] = 5
my_ratings[97] = 2
my_ratings[98] = 5
my_ratings[150] = 4
my_ratings[154] = 4
my_ratings[175] = 3
my_ratings[312] = 5

for i,r in enumerate(my_ratings):
    if r>0:
        print('Rated {0} for {1}'.format(int(r[0]), movie_list[i]))

mat = scipy.io.loadmat('data/ex8_movies.mat')
Y = np.hstack((my_ratings,mat['Y']))
R = np.hstack((my_ratings!=0,mat['R']))

Y.shape

"""#### Training Collaborative Filtering"""

def normalize_ratings(Y, R):
    Y_mean = np.zeros((Y.shape[0], 1))
    Y_norm = np.zeros(Y.shape)
    for i in range(Y.shape[0]):
        idx = np.argwhere(R[i,:]==1).T[0]
        Y_mean[i] = np.mean(Y[i,idx], axis=0)
        Y_norm[i,idx] = np.subtract(Y[i,idx], Y_mean[i])
    return Y_norm, Y_mean

Y_norm, Y_mean = normalize_ratings(Y, R)

num_users = Y.shape[1]
num_movies = Y.shape[0]
num_features = 10

X = np.random.normal(size=(num_movies, num_features))
Theta = np.random.normal(size=(num_users, num_features))
initial_params = np.hstack((X.ravel(order='F'), Theta.ravel(order='F')))

import scipy.optimize as opt
lambda_r = 10
opt_results = opt.minimize(cofi_cost_func, initial_params, args=(Y, R, num_users, num_movies, num_features, lambda_r),
                           method='L-BFGS-B', jac=True, options={'maxiter':100})
theta = opt_results['x']

X = np.reshape(theta[:num_movies*num_features], newshape=(num_movies, num_features), order='F')
Theta = np.reshape(theta[num_movies*num_features:], newshape=(num_users, num_features), order='F')

"""#### Recommendation"""

p = X.dot(Theta.T)
my_predictions = p[:,0] + Y_mean.T[0]

sort_idxs = np.argsort(my_predictions)[::-1]
print('Top recommendations for you:')
for i in range(10):
    j = sort_idxs[i]
    print('Predicting rating {0} for movie {1}'.format(my_predictions[j], movie_list[j]))

print('Original ratings provided:')
for i,r in enumerate(my_ratings):
    if r>0:
        print('Rated {0} for {1}'.format(int(r[0]), movie_list[i]))

